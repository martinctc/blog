I"Û<section class="main-content">
<div id="background" class="section level2">
<h2>Background</h2>
<p>One of the pet projects that I had been working on earlier in the year was to figure out an efficient way to gain an insight into what is going on in a consumer market, e.g.:</p>
<ul>
<li>What do people look for when they‚Äôre buying a product?</li>
<li>What are the typical pain points / causes of frustration in the purchase process or in a product itself?</li>
</ul>
<p>There are many ways to do this: usage and attitude surveys, qualitative focus groups, online bulletin-board style platform, social media mining, etc. But most of these methods take a lot of time and cost to set up, and may not be suitable if you‚Äôre trying to have a quick glimpse of what‚Äôs happening.</p>
<p><strong>Amazon reviews</strong> provide a fast, accessible yet vast data resource that does both of these things, allowing you to quickly explore what‚Äôs going on at effectively zero data collection cost. In this blog post, I‚Äôll go through some examples of how all this could be done in R with relatively few lines of code.</p>
<p><strong>Note</strong> : As a data collection activity, web-scraping may have legal implications depending on your country. For the UK, as a general rule you can legally web-scrape anything out there that is in the public domain, but it is recommended that you obtain the site owner‚Äôs permission if you are reporting on the data or using the data for commercial use (See this <a href="https://benbernardblog.com/web-scraping-and-crawling-are-perfectly-legal-right/">post</a> for a more in-depth discussion)</p>
<hr />
</div>
<div id="getting-started" class="section level2">
<h2>Getting Started üöÄ</h2>
<p>The first step is to load the <strong>tidyverse</strong> and <strong>rvest</strong> packages, as we‚Äôll need them for building the webscraping function (e.g.¬†parsing html) and for general data manipulation:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)<span class="kw">
library</span>(rvest)</code></pre></div>
<p>The next step is to find out the <em>ASIN</em> (stands for Amazon Standard Identification Number) of the product that you want to extract reviews from. This is effectively a product ID, which can usually be found within the URL of the product link itself. ASINS are unique strings of 10 characters, where for books this would be the same as the ISBN number.</p>
<p>For our example, let‚Äôs use the seven volume paperback collection of George R R Martin‚Äôs <em>A Song of Ice and Fire</em>, which has almost 2.5K reviews on Amazon.co.uk at the time of writing. We can also specify the number of review pages to scrape, where the fixed number of reviews per page is ten. In this example, the ASIN is <code>0007477155</code>, and you can find the link to the product by combining the ASIN with ‚Äú<a href="https://www.amazon.co.uk/dp/" class="uri">https://www.amazon.co.uk/dp/</a>‚Äù:</p>
<p><img src="http://localhost:4000/blog\images\amazon_got.PNG" width="80%" /></p>
<p>To my knowledge, the URL structure works the same way for Amazon US and Amazon UK - you can simply change the URL root to make this work for the different websites (replace ‚Äò.co.uk‚Äô with ‚Äò.com‚Äô). Whether this will continue to work in the future will be dependent on whether Amazon changes the set-up of the URLs.</p>
<hr />
</div>
<div id="writing-the-review-scraping-function" class="section level2">
<h2>Writing the review scraping function</h2>
<p>The next step is to write the main workhorse function for scraping the reviews.</p>
<p>In essence, what we are trying to achieve is to download the HTML content from the Amazon review page, and then use various html parsing and selector functions to organise the downloaded content into an easily manipulable format.</p>
<p>The <code>read_html()</code> function from the <strong>xml2</strong> package reads the HTML content from a given URL, which you can assign to an object in R (so you don‚Äôt have to keep re-downloading the website) and figure out how to extract content from the object.</p>
<p>In this specific example of scraping Amazon reviews, our objective is to get to a table that has the following three basic columns:</p>
<ul>
<li>Title of the Review</li>
<li>Body / Content of the Review</li>
<li>Rating given for the Review</li>
</ul>
<p>The trick is to use a combination of <code>html_nodes()</code> and <code>html_text()</code> from the <strong>rvest</strong> package to lock onto the content that you need (The <strong>rvest</strong> package recommends <a href="http://flukeout.github.io/">this</a> really cool site for learning how to use CSS selectors).</p>
<p>In my function, I assign all the bits of extracted content (review title, review body text, and star rating) into individual objects, and combine them into a tidy tibble to make it easy for data analysis.</p>
<p>Let‚Äôs call this function <code>scrape_amazon()</code>, and allow it to take in the ASIN and the page number as the two arguments:</p>
</div></section>
:ET